{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from loadData import loaddata as ld\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/wine+quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0            7.4              0.70         0.00             1.9      0.076   \n1            7.8              0.88         0.00             2.6      0.098   \n2            7.8              0.76         0.04             2.3      0.092   \n3           11.2              0.28         0.56             1.9      0.075   \n4            7.4              0.70         0.00             1.9      0.076   \n\n   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                 11.0                  34.0   0.9978  3.51       0.56   \n1                 25.0                  67.0   0.9968  3.20       0.68   \n2                 15.0                  54.0   0.9970  3.26       0.65   \n3                 17.0                  60.0   0.9980  3.16       0.58   \n4                 11.0                  34.0   0.9978  3.51       0.56   \n\n   alcohol  quality  \n0      9.4        5  \n1      9.8        5  \n2      9.8        5  \n3      9.8        6  \n4      9.4        5  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.9978</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.88</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.9968</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.76</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.9970</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.28</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.9980</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.70</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.9978</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "file_name = 'winequality-red.csv'\n",
    "ld(link, file_name)\n",
    "df = pd.read_csv(path.abspath(path.curdir) + '\\\\data\\\\' + file_name)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Оцените качество по метрике accuracy для классификаторов:\n",
    "\n",
    "DecisionTreeClassifier\n",
    "\n",
    "BaggingClassifier со 100 деревьями\n",
    "\n",
    "RandomForestClassifier со 100 деревьями\n",
    "\n",
    "Сравните результаты и напишите какой вывод можно сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_X = df.drop(columns='quality')\n",
    "df_y = df['quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: 0.5875\n",
      "BaggingClassifier: 0.6375\n",
      "RandomForestClassifier: 0.665625\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "btc = BaggingClassifier().fit(X_train, y_train)\n",
    "rfc = RandomForestClassifier().fit(X_train, y_train)\n",
    "print(str(dtc)[:-2] + ': ' + str(accuracy_score(y_test, dtc.predict(X_test))))\n",
    "print(str(btc)[:-2] + ': ' + str(accuracy_score(y_test, btc.predict(X_test))))\n",
    "print(str(rfc)[:-2] + ': ' + str(accuracy_score(y_test, rfc.predict(X_test))))\n",
    "# accuracy_score()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Разделите выборку на обучающую и тестовую в отношении 70%/30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, train_size=0.7, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Посчитайте качество на тестовой выборке по метрике accuracy для классификатора RandomForestClassifier, используя значения деревьев:\n",
    "    \n",
    "10, 50, 100, 200, далее с шагом 200 до 5000 деревьев.\n",
    "Постройте график зависимости качества от числа деревьев.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [02:29<00:00,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier, кол. деревьев 10: 0.6291666666666667\r\n",
      "RandomForestClassifier, кол. деревьев 50: 0.6916666666666667\r\n",
      "RandomForestClassifier, кол. деревьев 100: 0.6916666666666667\r\n",
      "RandomForestClassifier, кол. деревьев 200: 0.69375\r\n",
      "RandomForestClassifier, кол. деревьев 400: 0.6895833333333333\r\n",
      "RandomForestClassifier, кол. деревьев 600: 0.6833333333333333\r\n",
      "RandomForestClassifier, кол. деревьев 800: 0.69375\r\n",
      "RandomForestClassifier, кол. деревьев 1000: 0.6833333333333333\r\n",
      "RandomForestClassifier, кол. деревьев 1200: 0.69375\r\n",
      "RandomForestClassifier, кол. деревьев 1400: 0.6875\r\n",
      "RandomForestClassifier, кол. деревьев 1600: 0.6833333333333333\r\n",
      "RandomForestClassifier, кол. деревьев 1800: 0.6875\r\n",
      "RandomForestClassifier, кол. деревьев 2000: 0.6895833333333333\r\n",
      "RandomForestClassifier, кол. деревьев 2200: 0.6895833333333333\r\n",
      "RandomForestClassifier, кол. деревьев 2400: 0.6958333333333333\r\n",
      "RandomForestClassifier, кол. деревьев 2600: 0.6833333333333333\r\n",
      "RandomForestClassifier, кол. деревьев 2800: 0.6875\r\n",
      "RandomForestClassifier, кол. деревьев 3000: 0.6854166666666667\r\n",
      "RandomForestClassifier, кол. деревьев 3200: 0.6916666666666667\r\n",
      "RandomForestClassifier, кол. деревьев 3400: 0.69375\r\n",
      "RandomForestClassifier, кол. деревьев 3600: 0.6895833333333333\r\n",
      "RandomForestClassifier, кол. деревьев 3800: 0.6875\r\n",
      "RandomForestClassifier, кол. деревьев 4000: 0.6875\r\n",
      "RandomForestClassifier, кол. деревьев 4200: 0.6833333333333333\r\n",
      "RandomForestClassifier, кол. деревьев 4400: 0.6916666666666667\r\n",
      "RandomForestClassifier, кол. деревьев 4600: 0.6854166666666667\r\n",
      "RandomForestClassifier, кол. деревьев 4800: 0.6916666666666667\r\n",
      "RandomForestClassifier, кол. деревьев 5000: 0.6895833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "ls_trees = [10, 50, 100] + np.arange(200, 5001, 200).tolist()\n",
    "ls_res = []\n",
    "for i in tqdm(range(len(ls_trees))):\n",
    "    rfc = RandomForestClassifier(n_estimators=ls_trees[i]).fit(X_train, y_train)\n",
    "    ls_res.append(str(rfc).split('(')[0] + ', кол. деревьев ' + str(ls_trees[i]) + ': '\n",
    "                  + str(accuracy_score(y_test, rfc.predict(X_test))))\n",
    "    # print(str(rfc)[:-2] + ' ' + str(ls_trees[i]) + ': ' + str(accuracy_score(rfc.predict(X_test), y_test)))\n",
    "print(*ls_res, sep='\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек sklearn и xgboost. Сравните значение метрики accuracy по cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GradientBoostingClassifier: 0.6729166666666667\n",
      "Accuracy of XGBClassifier: 0.675\n",
      "CrossValScore of GradientBoostingClassifier: 0.5672315830721003\n",
      "CrossValScore of XGBClassifier: 0.5472335423197492\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=Warning)\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "gbc = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "cvs_gbc = cross_val_score(gbc, df_X, df_y)\n",
    "xgbc = XGBClassifier(eval_metric='mlogloss').fit(X_train, y_train)\n",
    "cvs_xgbc = cross_val_score(xgbc, df_X, df_y)\n",
    "print('Accuracy of ' + str(gbc).split('(')[0] + ': ' + str(accuracy_score(y_test, gbc.predict(X_test))))\n",
    "print('Accuracy of ' + str(xgbc).split('(')[0] + ': ' + str(accuracy_score(y_test, xgbc.predict(X_test))))\n",
    "print('CrossValScore of ' + str(gbc).split('(')[0] + ': ' + str(cvs_gbc.mean()))\n",
    "print('CrossValScore of ' + str(xgbc).split('(')[0] + ': ' + str(cvs_xgbc.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Подберите оптимальные параметры этих алгоритмов с помощью GridSearchCV(cv=3).\n",
    "Параметры для оптимизации:\n",
    "- оптимизируемый функционал\n",
    "- скорость обучения\n",
    "- количество деревьев\n",
    "- глубина деревьев\n",
    "\n",
    "Сравните значение метрики accuracy и скорость работы. Выведите лучшие параметры алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запускаем подбор параметров для классификатора GradientBoostingClassifier. Подбор отработал за: 00:10:14\n",
      "Запускаем подбор параметров для классификатора XGBClassifier. Подбор отработал за: 00:02:21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "loss = ['deviance']\n",
    "learn_rate = [0.01, 0.1, 0.2, 0.3, 0.4] # learning_rate\n",
    "depth_trees = list(range(4,7)) # max_depth\n",
    "quantity_trees = list(range(175,276, 25)) # n_estimators\n",
    "\n",
    "params_gbc = {'loss': loss,'max_depth': depth_trees, 'n_estimators': quantity_trees, 'learning_rate': learn_rate}\n",
    "params_xgbc = {'objective': loss,'max_depth': depth_trees, 'n_estimators': quantity_trees, 'learning_rate': learn_rate}\n",
    "\n",
    "ls_results = []\n",
    "\n",
    "for i_est, i_params in [[GradientBoostingClassifier(), params_gbc], [XGBClassifier(eval_metric='mlogloss'), params_xgbc]]:\n",
    "    warnings.filterwarnings(action='ignore', category=Warning)\n",
    "    gs = GridSearchCV(estimator=i_est, param_grid=i_params, cv=3, verbose=0)\n",
    "    print('Запускаем подбор параметров для классификатора ' + str(i_est).split('(')[0], end='. ')\n",
    "    t_start = time.time()\n",
    "    gs.fit(X_train, y_train)\n",
    "    t_end = time.time()\n",
    "    print('Подбор отработал за: ' + time.strftime('%H:%M:%S', time.gmtime(t_end-t_start)))\n",
    "    ls_results.append([gs.best_estimator_,\n",
    "                      accuracy_score(y_test, gs.best_estimator_.predict(X_test)),\n",
    "                      time.strftime('%H:%M:%S', time.gmtime(t_end-t_start))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                          clf  accuracy      time            loss  max_depth  \\\n0  GradientBoostingClassifier  0.660417  00:10:14        deviance          5   \n1               XGBClassifier  0.664583  00:02:21  multi:softprob          6   \n\n   learning_rate  n_estimators  \n0           0.01           250  \n1           0.10           225  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clf</th>\n      <th>accuracy</th>\n      <th>time</th>\n      <th>loss</th>\n      <th>max_depth</th>\n      <th>learning_rate</th>\n      <th>n_estimators</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>GradientBoostingClassifier</td>\n      <td>0.660417</td>\n      <td>00:10:14</td>\n      <td>deviance</td>\n      <td>5</td>\n      <td>0.01</td>\n      <td>250</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>XGBClassifier</td>\n      <td>0.664583</td>\n      <td>00:02:21</td>\n      <td>multi:softprob</td>\n      <td>6</td>\n      <td>0.10</td>\n      <td>225</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_results[0].append(str(ls_results[0][0]).split('(')[0])\n",
    "ls_results[0].append((ls_results[0][0]).get_params().get('loss'))\n",
    "ls_results[0].append((ls_results[0][0]).get_params().get('max_depth'))\n",
    "ls_results[0].append((ls_results[0][0]).get_params().get('learning_rate'))\n",
    "ls_results[0].append((ls_results[0][0]).get_params().get('n_estimators'))\n",
    "ls_results[1].append(str(ls_results[1][0]).split('(')[0])\n",
    "ls_results[1].append((ls_results[1][0]).get_params().get('objective'))\n",
    "ls_results[1].append((ls_results[1][0]).get_params().get('max_depth'))\n",
    "ls_results[1].append((ls_results[1][0]).get_params().get('learning_rate'))\n",
    "ls_results[1].append((ls_results[1][0]).get_params().get('n_estimators'))\n",
    "(pd.DataFrame(ls_results, columns=['estimator', 'accuracy', 'time', 'clf', 'loss', 'max_depth', 'learning_rate', 'n_estimators']).drop(columns='estimator'))[['clf', 'accuracy', 'time', 'loss', 'max_depth', 'learning_rate', 'n_estimators']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Обучите реализации градиентного бустинга с параметрами по умолчанию из библиотек lightgbm и catboost. Сравните значение метрики accuracy по cross_val_score по всем четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                           estimator     cross_val_score\n3                         GradientBoostingClassifier  0.5684855015673981\n0                                     LGBMClassifier  0.5566222570532915\n2                                      XGBClassifier  0.5472335423197492\n1  <catboost.core.CatBoostClassifier object at 0x...  0.5459757053291535",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>estimator</th>\n      <th>cross_val_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>GradientBoostingClassifier</td>\n      <td>0.5684855015673981</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>LGBMClassifier</td>\n      <td>0.5566222570532915</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>XGBClassifier</td>\n      <td>0.5472335423197492</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;catboost.core.CatBoostClassifier object at 0x...</td>\n      <td>0.5459757053291535</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "estimators = [LGBMClassifier().set_params(verbosity=-1), CatBoostClassifier(verbose=0), XGBClassifier(verbosity=0, eval_metric='mlogloss'), GradientBoostingClassifier(verbose=0)]\n",
    "\n",
    "ls_results = []\n",
    "\n",
    "for est in estimators:\n",
    "    ls_results.append([str(est).split('(')[0], str(cross_val_score(estimator=est, X=df_X, y=df_y, scoring='accuracy').mean())])\n",
    "\n",
    "pd.DataFrame(ls_results, columns=['estimator', 'cross_val_score']).sort_values(by='cross_val_score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Подберите оптимальные параметры для алгоритмов градиентного бустинга из библиотек lightgbm и catboost с теми же условиями. Выведите лучшие параметры алгоритмов.\n",
    "Сравните значение метрики accuracy и скорость по этим четырем реализациям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запускаем подбор параметров для классификатора LGBMClassifier. Подбор отработал за: 00:01:23\n",
      "Запускаем подбор параметров для классификатора <catboost.core.CatBoostClassifier object at 0x000001E59B357688>. Подбор отработал за: 00:02:28\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth': depth_trees, 'n_estimators': quantity_trees, 'learning_rate': learn_rate}\n",
    "\n",
    "\n",
    "ls_results = []\n",
    "\n",
    "for i_est in [LGBMClassifier().set_params(verbosity=-1), CatBoostClassifier(verbose=0)]:\n",
    "    warnings.filterwarnings(action='ignore', category=Warning)\n",
    "    gs = GridSearchCV(estimator=i_est, param_grid=params, cv=3, verbose=0)\n",
    "    print('Запускаем подбор параметров для классификатора ' + str(i_est).split('(')[0], end='. ')\n",
    "    t_start = time.time()\n",
    "    gs.fit(X_train, y_train)\n",
    "    t_end = time.time()\n",
    "    print('Подбор отработал за: ' + time.strftime('%H:%M:%S', time.gmtime(t_end-t_start)))\n",
    "    ls_results.append([gs.best_estimator_,\n",
    "                      accuracy_score(y_test, gs.best_estimator_.predict(X_test)),\n",
    "                      time.strftime('%H:%M:%S', time.gmtime(t_end-t_start))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           estimator  accuracy      time  \\\n0                                     LGBMClassifier  0.658333  00:01:23   \n1  <catboost.core.CatBoostClassifier object at 0x...  0.668750  00:02:28   \n\n   max_depth  n_estimators  learning_rate  \n0          4           250            0.3  \n1          6           275            0.1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>estimator</th>\n      <th>accuracy</th>\n      <th>time</th>\n      <th>max_depth</th>\n      <th>n_estimators</th>\n      <th>learning_rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LGBMClassifier</td>\n      <td>0.658333</td>\n      <td>00:01:23</td>\n      <td>4</td>\n      <td>250</td>\n      <td>0.3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;catboost.core.CatBoostClassifier object at 0x...</td>\n      <td>0.668750</td>\n      <td>00:02:28</td>\n      <td>6</td>\n      <td>275</td>\n      <td>0.1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_best_results = []\n",
    "for result in ls_results:\n",
    "    dict_result = dict()\n",
    "    dict_result['estimator'] = str(result[0]).split('(')[0]\n",
    "    dict_result['accuracy'] = result[1]\n",
    "    dict_result['time'] = result[2]\n",
    "    for param in params.keys():\n",
    "        dict_result[param] = result[0].get_params().get(param)\n",
    "    ls_best_results.append(dict_result)\n",
    "\n",
    "pd.DataFrame(ls_best_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.Подберите оптимальные параметры алгоритма из библиотеки xgbost с помощью [hyperopt](https://github.com/hyperopt/hyperopt) . Параметры для оптимизации:\n",
    "\n",
    "оптимизируемый функционал\n",
    "\n",
    "скорость обучения\n",
    "\n",
    "количество деревьев\n",
    "\n",
    "глубина деревьев\n",
    "\n",
    "Сравните результат с поиском по сетке из sklearn. Выведите лучшие параметры алгоритма, найденные даным способом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [4, 5, 6], 'n_estimators': [175, 200, 225, 250, 275], 'learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4]}\n",
      "100%|██████████| 15/15 [00:11<00:00,  1.27trial/s, best loss: -0.6791666666666667]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'learning_rate': 0.4, 'max_depth': 4, 'n_estimators': 175}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, space_eval\n",
    "\n",
    "print(params)\n",
    "\n",
    "hp_params = {}\n",
    "for i_params in params.keys():\n",
    "\n",
    "    hp_params[i_params] = hp.choice(i_params, np.array(params.get(i_params)))\n",
    "\n",
    "hp_params\n",
    "\n",
    "def hyperopt_xgb_score(params):\n",
    "    clf = XGBClassifier(**params, eval_metric='mlogloss')\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
    "    # print(accuracy, params)\n",
    "    return -accuracy\n",
    "\n",
    "res = fmin(fn=hyperopt_xgb_score, space=hp_params, algo=tpe.suggest, max_evals=15)\n",
    "space_eval(hp_params, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.Выведите качество по метрике accuracy стэкинга (StackingClassifier) 4-х алгоритмов с базовыми параметрами градиентного бустинга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.7020833333333333"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "estim_names = ['lgbm', 'catboost', 'xgbc', 'gradient_boosting']\n",
    "sc_estimators = [(estim_names[i], estimators[i]) for i in range(len(estimators))]\n",
    "\n",
    "sc = StackingClassifier(sc_estimators)\n",
    "sc.fit(X_train, y_train)\n",
    "sc.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.Выведите качество по метрике accuracy стэкинга 4-х алгоритмов с оптимальными параметрами градиентного бустинга. Сравните результаты с предыдущим шагом и напишите какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.6958333333333333"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estim_names = ['lgbm', 'catboost', 'xgbc', 'gradient_boosting']\n",
    "estimators_hp = [i.set_params(**space_eval(hp_params, res)) for i in estimators]\n",
    "sc_hp_estimators = [(estim_names[i], estimators_hp[i]) for i in range(len(estimators_hp))]\n",
    "\n",
    "sc = StackingClassifier(sc_hp_estimators)\n",
    "sc.fit(X_train, y_train)\n",
    "sc.score(X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}